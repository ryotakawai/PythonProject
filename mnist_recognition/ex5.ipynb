{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.2　グリッドサーチ２"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mnist-train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\210450279\\Anaconda3\\envs\\rebases\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py:1750: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "step 0, train_loss 2.30, val_loss 2.30, train_acc 0.12, val_acc 0.10\n",
      "step 500, train_loss 1.01, val_loss 0.80, train_acc 0.72, val_acc 0.76\n",
      "step 1000, train_loss 0.49, val_loss 0.51, train_acc 0.84, val_acc 0.86\n",
      "step 1500, train_loss 0.36, val_loss 0.38, train_acc 0.88, val_acc 0.89\n",
      "step 2000, train_loss 0.18, val_loss 0.32, train_acc 0.97, val_acc 0.91\n",
      "step 2500, train_loss 0.30, val_loss 0.30, train_acc 0.88, val_acc 0.91\n",
      "step 3000, train_loss 0.44, val_loss 0.26, train_acc 0.88, val_acc 0.92\n",
      "step 3500, train_loss 0.18, val_loss 0.24, train_acc 0.97, val_acc 0.93\n",
      "step 4000, train_loss 0.17, val_loss 0.23, train_acc 0.97, val_acc 0.94\n",
      "step 4500, train_loss 0.11, val_loss 0.21, train_acc 0.97, val_acc 0.94\n",
      "step 5000, train_loss 0.17, val_loss 0.20, train_acc 0.97, val_acc 0.94\n",
      "step 5500, train_loss 0.07, val_loss 0.19, train_acc 1.00, val_acc 0.94\n",
      "step 6000, train_loss 0.29, val_loss 0.18, train_acc 0.88, val_acc 0.95\n",
      "step 6500, train_loss 0.10, val_loss 0.18, train_acc 0.97, val_acc 0.94\n",
      "step 7000, train_loss 0.06, val_loss 0.17, train_acc 1.00, val_acc 0.95\n",
      "step 7500, train_loss 0.18, val_loss 0.17, train_acc 0.97, val_acc 0.95\n",
      "step 8000, train_loss 0.04, val_loss 0.16, train_acc 1.00, val_acc 0.95\n",
      "step 8500, train_loss 0.24, val_loss 0.15, train_acc 0.94, val_acc 0.95\n",
      "step 9000, train_loss 0.07, val_loss 0.15, train_acc 0.97, val_acc 0.96\n",
      "step 9500, train_loss 0.31, val_loss 0.15, train_acc 0.91, val_acc 0.95\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'model3/my-model'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "# 再現性の確保のために乱数シードを固定（数値は何でもよい）\n",
    "tf.set_random_seed(12345)\n",
    "\n",
    "# 入力データ\n",
    "# MNISTのワンホット表現での読み込み\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True, validation_size=10000)\n",
    "\n",
    "# 0 入力画像\n",
    "x = tf.placeholder(tf.float32, name='x')\n",
    "\n",
    "# 1 サイズ変更\n",
    "x_1 = tf.reshape(x, [-1, 28, 28, 1])\n",
    "\n",
    "# 2 畳み込み\n",
    "# ランダムカーネル\n",
    "k_0 = tf.Variable(tf.truncated_normal([4, 4, 1, 10], mean=0.0, stddev=0.1))\n",
    "# 畳み込み\n",
    "x_2 = tf.nn.conv2d(x_1, k_0, strides=[1, 3, 3, 1], padding='VALID')\n",
    "\n",
    "# 3 活性化関数\n",
    "x_3 = tf.nn.relu(x_2)\n",
    "\n",
    "# 4 プーリング\n",
    "x_4 = tf.nn.max_pool(x_3, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
    "\n",
    "# 5 サイズ変更\n",
    "x_5 = tf.reshape(x_4, [-1, 160])\n",
    "\n",
    "#ドロップアウト付きの全結合\n",
    "def matmul_plus_bias_with_dropout(x, w, b, p):\n",
    "    return tf.matmul(tf.nn.dropout(x, keep_prob=p), w) + b\n",
    "\n",
    "# 6 全結合\n",
    "# 重みとバイアス\n",
    "w_1 = tf.Variable(tf.zeros([160, 40]))\n",
    "b_1 = tf.Variable([0.1] * 40)\n",
    "#ドロップアウト率\n",
    "p_1 = tf.placeholder(tf.float32, name='p_1')\n",
    "# 全結合\n",
    "x_6 = matmul_plus_bias_with_dropout(x_5, w_1, b_1, p_1)\n",
    "\n",
    "# 7 活性化関数\n",
    "x_7 = tf.nn.relu(x_6)\n",
    "\n",
    "# 8 全結合\n",
    "# 重みとバイアス\n",
    "w_2 = tf.Variable(tf.zeros([40, 10]))\n",
    "b_2 = tf.Variable([0.1] * 10)\n",
    "#ドロップアウト率\n",
    "p_2 = tf.placeholder(tf.float32, name='p_2')\n",
    "# 全結合\n",
    "x_8 = matmul_plus_bias_with_dropout(x_7, w_2, b_2, p_2)\n",
    "\n",
    "# 9 確率化\n",
    "y = tf.nn.softmax(x_8, name='y')\n",
    "\n",
    "# 10 損失関数の最小化\n",
    "# 正解ラベル\n",
    "labels = tf.placeholder(tf.float32, name='labels')\n",
    "# 損失関数（交差エントロピー）と最適化処理（Adam）\n",
    "loss = -tf.reduce_sum(labels * tf.log(y)) / tf.cast(tf.shape(y)[0], tf.float32)\n",
    "optimizer = tf.train.AdamOptimizer().minimize(loss)\n",
    "\n",
    "# 11 精度検証 (Top-1 accuracy)\n",
    "prediction_match = tf.equal(tf.argmax(y, axis=1), tf.argmax(labels, axis=1))\n",
    "accuracy = tf.reduce_mean(tf.cast(prediction_match, tf.float32), name='accuracy')\n",
    "\n",
    "# 損失関数と精度の出力をトレース対象とする\n",
    "loss_summary = tf.summary.scalar('loss', loss)\n",
    "accuracy_summary = tf.summary.scalar('accuracy', accuracy)\n",
    "summary = tf.summary.merge([loss_summary, accuracy_summary])\n",
    "\n",
    "# パラメーター\n",
    "# バッチサイズ\n",
    "BATCH_SIZE = 32\n",
    "# 学習回数\n",
    "NUM_TRAIN = 10_000\n",
    "# 学習中の出力頻度\n",
    "OUTPUT_BY = 500\n",
    "#ドロップアウト率\n",
    "DROPOUT_PROB_1 = 0.8\n",
    "DROPOUT_PROB_2 = 0.8\n",
    "\n",
    "# 以前のログが残っていれば削除する（通常は残すようにしてください）\n",
    "logdir = Path('logs/log3')\n",
    "if logdir.exists():\n",
    "    shutil.rmtree(str(logdir))\n",
    "\n",
    "# 学習の実行\n",
    "# TensorBoard上でグラフを重ねて描くために、2つのwriterを使用する\n",
    "with tf.summary.FileWriter('logs/log3/train') as train_writer, \\\n",
    "    tf.summary.FileWriter('logs/log3/val') as val_writer:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    dropout_prob = {p_1: DROPOUT_PROB_1, p_2: DROPOUT_PROB_2}\n",
    "    saver = tf.train.Saver()\n",
    "    for i in range(NUM_TRAIN):\n",
    "        batch = mnist.train.next_batch(BATCH_SIZE)\n",
    "        inout = {x: batch[0], labels: batch[1]}\n",
    "        if i % OUTPUT_BY == 0:\n",
    "            train_loss, train_accuracy, train_summary = \\\n",
    "                sess.run([loss, accuracy, summary], feed_dict={**inout, p_1: 1.0, p_2: 1.0})\n",
    "            val_loss, val_accuracy, val_summary = \\\n",
    "                sess.run([loss, accuracy, summary], feed_dict={\n",
    "                x: mnist.validation.images, labels: mnist.validation.labels, p_1: 1.0, p_2: 1.0})\n",
    "            print('step {:d}, train_loss {:.2f}, val_loss {:.2f}, train_acc {:.2f}, val_acc {:.2f}'.format(\n",
    "                i, train_loss, val_loss, train_accuracy, val_accuracy))\n",
    "            # ログの出力\n",
    "            train_writer.add_summary(train_summary, global_step=i)\n",
    "            val_writer.add_summary(val_summary, global_step=i)\n",
    "            # 過程の保存\n",
    "            saver.save(sess, 'model3/my-model', global_step=i)\n",
    "            # ファイルへの強制書き出し\n",
    "            train_writer.flush()\n",
    "            val_writer.flush()\n",
    "        optimizer.run(feed_dict={**inout, **dropout_prob})\n",
    "\n",
    "# 最終結果の保存\n",
    "saver.save(sess, 'model3/my-model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mnist-test.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from model3/my-model\n",
      "test accuracy 0.96\n"
     ]
    }
   ],
   "source": [
    "# モデルの読み込み\n",
    "saver = tf.train.import_meta_graph('model3/my-model.meta')\n",
    "\n",
    "# データフローグラフからプレースホルダーと精度測定処理ノードを取得\n",
    "graph = tf.get_default_graph()\n",
    "x = graph.get_tensor_by_name('x:0')\n",
    "labels = graph.get_tensor_by_name('labels:0')\n",
    "p_1 = graph.get_tensor_by_name('p_1:0')\n",
    "p_2 = graph.get_tensor_by_name('p_2:0')\n",
    "y = graph.get_tensor_by_name('y:0')\n",
    "accuracy = graph.get_tensor_by_name('accuracy:0')\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # 変数初期化\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    # モデル読み込み\n",
    "    saver.restore(sess, 'model3/my-model')\n",
    "\n",
    "    # テストデータによる精度検証\n",
    "    test_accuracy = accuracy.eval(feed_dict={x: mnist.test.images, labels: mnist.test.labels, p_1: 1.0, p_2: 1.0})\n",
    "    print('test accuracy {:.2f}'.format(test_accuracy))\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f5bb542c5f8ffcfc7fda68624d38253a8d24c155b1e912518077c095286d0bbc"
  },
  "kernelspec": {
   "display_name": "Python 3.6.10 ('rebases')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
