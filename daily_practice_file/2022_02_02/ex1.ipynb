{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-6ab59f318498>:6: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n"
     ]
    }
   ],
   "source": [
    "# 画像をグレースケールで読み込み、浮動小数点数データに変換する。\n",
    "# tf.read_file()はファイルシステムからファイルの内容(バイト列)を取得する。\n",
    "png = tf.read_file('03-02-original.png')\n",
    "# バイト列をテンソルに変換(デコード)する。\n",
    "image = tf.image.decode_png(png, channels=1, dtype=tf.uint8)  \n",
    "image_float = tf.to_float(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.nn.conv2dメソッドを適用するために4階のテンソルに変換\n",
    "# 4階のテンソルはそれぞれ「バッチサイズ、画像横幅、画像縦幅、チャンネル」\n",
    "image_reshape = tf.reshape(image_float, [-1, 32, 32, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# カーネル(フィルター)の作成\n",
    "kernel = tf.constant(\n",
    "    [\n",
    "        [0, -1, -1, -1, 0],\n",
    "        [-1, 0, 3, 0, -1],\n",
    "        [-1, 3, 0, 3, -1],\n",
    "        [-1, 0, 3, 0, -1],\n",
    "        [0, -1, -1, -1, 0]\n",
    "    ],\n",
    "    dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.nn.conv2dメソッドを適用するために4階のテンソルに変換\n",
    "# 4階のテンソルはそれぞれ「横幅、縦幅、入力チャンネル、出力チャンネル」\n",
    "kernel_reshape = tf.reshape(kernel, [5, 5, 1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ストライド幅3\n",
    "# 3ピクセルずつ動かす\n",
    "strides = [1, 3, 3, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 畳み込み tf.nn.conv2d()\n",
    "convolution_result = tf.nn.conv2d(\n",
    "    image_reshape,\n",
    "    kernel_reshape,\n",
    "    strides=strides,\n",
    "    # パディング：'VALID'はパディング無効\n",
    "    padding='VALID'   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  28., -165.,   84.,  -76.,  -77.,  193.,   48.,  113.,  -75.,\n",
       "         -71.],\n",
       "       [   8.,   60.,   -2.,   30.,  -89.,  -17.,  119.,  -75.,  -37.,\n",
       "          27.],\n",
       "       [  72., -221., -123., -147.,  -28.,  125., -104.,    2.,   20.,\n",
       "         -59.],\n",
       "       [ 133.,  109.,  206.,  173.,   97.,   92.,    1.,  -56.,  -22.,\n",
       "          54.],\n",
       "       [-286.,   47.,  -45.,  103.,  -51.,  -99.,   13.,  110.,  -22.,\n",
       "          78.],\n",
       "       [ 112.,   49.,   64.,  -91.,  -29., -180.,   87.,   -7.,  210.,\n",
       "         133.],\n",
       "       [ -49.,  -88.,   53.,  -77.,  -42.,  110., -103.,  116., -280.,\n",
       "          88.],\n",
       "       [ -72.,    3.,   79.,  176., -194.,  139., -319.,   57.,  175.,\n",
       "        -177.],\n",
       "       [ 161., -136.,  -51.,  107.,    1.,  -10.,  560., -105.,   93.,\n",
       "         -99.],\n",
       "       [ -64.,   44.,   85.,   52.,  -59.,   71., -101.,   -1.,  -98.,\n",
       "          81.]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 結果を見やすいように2階のテンソル(行列)に変換\n",
    "tf.reshape(convolution_result, [10, 10]).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 畳み込み\n",
    "convolution_result_with_padding = tf.nn.conv2d(\n",
    "    image_reshape,\n",
    "    kernel_reshape,\n",
    "    strides=strides,\n",
    "    # パディング：'SAME'はゼロパディング(画像の周囲に数値0のパディングを埋める)\n",
    "    padding='SAME'   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  76.,  238.,  221.,  321.,  194.,  326.,  346.,  115.,  166.,\n",
       "          99.,  386.],\n",
       "       [ 196.,  -16.,   53.,   27.,   32.,   62.,   53., -168.,  -17.,\n",
       "         174.,   65.],\n",
       "       [ 254.,  -57., -115.,   -9.,   59.,    6.,   88.,  101.,  -45.,\n",
       "          25.,  140.],\n",
       "       [ 301.,  -68., -122.,   70.,  161., -190.,    4.,   74., -174.,\n",
       "        -109.,  233.],\n",
       "       [  94.,   89.,    6.,   23.,   91., -119., -131.,  -57.,  328.,\n",
       "          41.,  119.],\n",
       "       [ 117.,   76.,   38., -165., -163.,  141.,   90.,   44.,   29.,\n",
       "          53.,   30.],\n",
       "       [ 236.,  -44.,   79.,   53.,    1.,   49.,  -46.,  145., -101.,\n",
       "         -76.,   59.],\n",
       "       [ 408., -203.,    8.,   85.,  -46.,   43.,  -26., -259.,  109.,\n",
       "         -97.,   97.],\n",
       "       [ 136.,  143.,  -26., -101.,   35.,   -5.,  359.,  339., -167.,\n",
       "        -127.,   89.],\n",
       "       [ 310.,  -71.,  -69.,  110., -184.,  -75., -201.,    9.,  -74.,\n",
       "           4.,  282.],\n",
       "       [ 327.,  259.,  149.,   80.,  167.,  212.,  161.,  -24.,  381.,\n",
       "         111.,  223.]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 結果を見やすいように2階のテンソル(行列)に変換\n",
    "tf.reshape(convolution_result_with_padding, [11, 11]).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最大値プーリング tf.nn.max_pool()\n",
    "pooling_result = tf.nn.max_pool(\n",
    "    convolution_result,\n",
    "    ksize=[1, 2, 2, 1],\n",
    "    strides=[1, 2, 2, 1],\n",
    "    padding='VALID'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 60.,  84., 193., 119.,  27.],\n",
       "       [133., 206., 125.,   2.,  54.],\n",
       "       [112., 103., -29., 110., 210.],\n",
       "       [  3., 176., 139., 116., 175.],\n",
       "       [161., 107.,  71., 560.,  93.]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 出力用のサイズ調整\n",
    "tf.reshape(pooling_result, [5, 5]).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 仮想のニューラルネットワークの出力\n",
    "y = tf.constant([1.1, 3.2, -0.9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.10750949, 0.87794065, 0.01454983], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ソフトマックス関数 tf.nn.softmax()\n",
    "p = tf.nn.softmax(y)\n",
    "p.eval()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a1c8c699d14e3903dc5150bb4eeb93a885371f7e5db0b28d0ec5cc4eff72bd11"
  },
  "kernelspec": {
   "display_name": "Python 3.6.13 64-bit ('introtensorflow': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
