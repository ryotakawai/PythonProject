{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# カレントスレッドにデフォルトのグラフが残存していることがあるので、リセットする\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 再現性の確保のために乱数シードを固定(数値は何でもよい)\n",
    "tf.set_random_seed(12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data2/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data2/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data2/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data2/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# 入力データ\n",
    "# MNISTのone-hot表現での読み込み\n",
    "mnist = input_data.read_data_sets(\"MNIST_data2/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 入力画像\n",
    "# プレースホルダー型で・・・\n",
    "x = tf.placeholder(tf.float32, name='x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# サイズ変更\n",
    "x_1 = tf.reshape(x, [-1, 28, 28, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ランダムカーネル\n",
    "k_0 = tf.Variable(tf.truncated_normal([4, 4, 1, 10], mean=0.0, stddev=0.1))\n",
    "\n",
    "# 畳み込み\n",
    "x_2 = tf.nn.conv2d(x_1, k_0, strides=[1, 3, 3, 1], padding='VALID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 活性化関数\n",
    "x_3 = tf.nn.relu(x_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# プーリング\n",
    "x_4 = tf.nn.max_pool(x_3, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1], padding='VALID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# サイズ変更\n",
    "x_5 = tf.reshape(x_4, [-1, 160])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ドロップアウト付きの全結合\n",
    "# tf.nn.dropout()の引数のkeep_propにノードを残す割合を指定する\n",
    "def matmul_plus_bias_with_dropout(x, w, b, p):\n",
    "    return tf.matmul(tf.nn.dropout(x, keep_prob=p), w) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 重みとバイアス\n",
    "w_1 = tf.Variable(tf.zeros([160, 40]))\n",
    "b_1 = tf.Variable([0.1] * 40)\n",
    "\n",
    "# ドロップアウト率\n",
    "p_1 = tf.placeholder(1.0, name='p_1')\n",
    "\n",
    "# 全結合\n",
    "# x_6 = tf.matmul(x_5, w_1) + b_1\n",
    "x_6 = matmul_plus_bias_with_dropout(x_5, w_1, b_1, p_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 活性化関数\n",
    "x_7 = tf.nn.relu(x_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 重みとバイアス\n",
    "w_2 = tf.Variable(tf.zeros([40, 10]))\n",
    "b_2 = tf.Variable([0.1] * 10)\n",
    "\n",
    "# ドロップアウト率\n",
    "p_2 = tf.placeholder(1.0, name='p_2')\n",
    "\n",
    "# 全結合\n",
    "# x_8 = tf.matmul(x_7, w_2) + b_2\n",
    "x_8 = matmul_plus_bias_with_dropout(x_7, w_2, b_2, p_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 確率化\n",
    "y = tf.nn.softmax(x_8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 損失関数の最小化\n",
    "\n",
    "# 正解ラベル\n",
    "labels = tf.placeholder(tf.float32, name='labels')\n",
    "\n",
    "# 損失関数(交差エントロピー誤差)\n",
    "# tf.reduce_sum() : 与えたリストに入っている数値の合計を求めるメソッド\n",
    "loss = -tf.reduce_sum(labels * tf.log(y))\n",
    "\n",
    "# 最適化処理(Adam)\n",
    "optimizer = tf.train.AdamOptimizer().minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 精度検証\n",
    "\n",
    "# tf.equal(x, y) : xとyが等しければTrue、等しくなければFalseを返す\n",
    "prediction_match = tf.equal(tf.argmax(y, axis=1), tf.argmax(labels, axis=1))\n",
    "\n",
    "# tf.reduce_mean() : 与えたリストに入っている数値の平均値を求めるメソッド\n",
    "# tf.cast() : 型を変換するメソッド　以下では第1引数がTrueなら、\n",
    "# それを第2引数のfloat型に変換する\n",
    "accuracy = tf.reduce_mean(tf.cast(prediction_match, tf.float32), name = \"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# パラメータ\n",
    "\n",
    "# バッチサイズ\n",
    "BATCH_SIZE = 32  \n",
    " \n",
    "# 学習回数\n",
    "NUM_TRAIN = 10_100  # 10_100 は 10,100 と同義\n",
    "\n",
    "# 学習中の出力精度\n",
    "OUTPUT_BY = 500\n",
    "\n",
    "# ドロップアウト率\n",
    "DROPOUT_PROB_1 = 0.2\n",
    "DROPOUT_PROB_2 = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step0, accuracy0.06\n",
      "step500, accuracy0.62\n",
      "step1000, accuracy0.59\n",
      "step1500, accuracy0.78\n",
      "step2000, accuracy0.66\n",
      "step2500, accuracy0.78\n",
      "step3000, accuracy0.81\n",
      "step3500, accuracy0.78\n",
      "step4000, accuracy0.94\n",
      "step4500, accuracy0.81\n",
      "step5000, accuracy0.81\n",
      "step5500, accuracy0.72\n",
      "step6000, accuracy0.84\n",
      "step6500, accuracy0.94\n",
      "step7000, accuracy0.78\n",
      "step7500, accuracy0.94\n",
      "step8000, accuracy0.91\n",
      "step8500, accuracy0.84\n",
      "step9000, accuracy0.78\n",
      "step9500, accuracy0.84\n",
      "step10000, accuracy0.84\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'models/my-model'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 学習の実行\n",
    "sess.run(tf.global_variables_initializer())\n",
    "dropout_prob = {p_1 : DROPOUT_PROB_1, p_2 : DROPOUT_PROB_2}\n",
    "\n",
    "# TensorFlowでは、モデルのファイル入出力は tf.train.Saver() を使う\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "for i in range(NUM_TRAIN):\n",
    "    # MNISTの訓練データから複数の画像データとラベルデータを取得(ミニバッチ学習)\n",
    "    batch = mnist.train.next_batch(BATCH_SIZE)\n",
    "    inout = {x : batch[0], labels : batch[1]}\n",
    "    if i % OUTPUT_BY == 0:\n",
    "        # train_accuracy = accuracy.eval(feed_dict=inout)\n",
    "        train_accuracy = accuracy.eval(feed_dict = {**inout, p_1 : 1.0, p_2 : 1.0})\n",
    "        print('step{:d}, accuracy{:.2f}'.format(i, train_accuracy))\n",
    "\n",
    "        # 過程の保存\n",
    "        saver.save(sess, 'models/my-model', global_step=i)\n",
    "\n",
    "    # optimizer.run(feed_dict=inout)\n",
    "    optimizer.run(feed_dict={**inout, **dropout_prob})\n",
    "\n",
    "# 最終結果の保存\n",
    "saver.save(sess, 'models/my-model')\n",
    "\n",
    "\"\"\"\n",
    "modelsの中に .data-00000-of-00001/.index/.meta という3つの拡張子が\n",
    "付いたファイル群とcheckpointファイルが作成される\n",
    "「過程の保存」では、ファイル名には「<モデル名>-<ステップ数>.<拡張子>」という名前で保存。\n",
    "「最終結果の保存」では、ファイル名には「<モデル名>.<拡張子>」という名前で保存。\n",
    "\n",
    ".metaファイルは、メタグラフというデータフローグラフ構造などの情報を保存したもの。\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_accuracy0.87\n"
     ]
    }
   ],
   "source": [
    "# テストデータによる精度検証\n",
    "# test_accuracy = accuracy.eval(feed_dict={x : mnist.test.images,\\\n",
    "#   labels : mnist.test.labels})\n",
    "test_accuracy = accuracy.eval(feed_dict={x : mnist.test.images,\\\n",
    "    labels : mnist.test.labels, p_1 : 1.0, p_2 :1.0})\n",
    "print('test_accuracy{:.2f}'.format(test_accuracy))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a1c8c699d14e3903dc5150bb4eeb93a885371f7e5db0b28d0ec5cc4eff72bd11"
  },
  "kernelspec": {
   "display_name": "Python 3.6.13 64-bit ('introtensorflow': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
